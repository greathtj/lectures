{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일단 라이브러리를 설치합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install djitellopy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일단, 기본적인 동작이 되는지 확인합니다.\n",
    "### 1) 비행이 되는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from djitellopy import Tello\n",
    "import time\n",
    "\n",
    "# Connect to Tello\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "\n",
    "# Takeoff\n",
    "tello.takeoff()\n",
    "time.sleep(2)\n",
    "\n",
    "# Move forward\n",
    "tello.move_forward(30)\n",
    "time.sleep(2)\n",
    "\n",
    "# Rotate clockwise\n",
    "tello.rotate_clockwise(45)\n",
    "time.sleep(2)\n",
    "\n",
    "# Land\n",
    "tello.land()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 화면은 오는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from djitellopy import Tello\n",
    "import cv2\n",
    "\n",
    "# Connect to Tello\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "\n",
    "# Start video stream\n",
    "tello.streamon()\n",
    "\n",
    "# OpenCV window to display video feed\n",
    "cv2.namedWindow(\"Tello Video Feed\")\n",
    "\n",
    "while True:\n",
    "    # Get frame from video stream\n",
    "    frame = tello.get_frame_read().frame\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Tello Video Feed\", frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Stop video stream\n",
    "tello.streamoff()\n",
    "\n",
    "# Close OpenCV window\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 배터리 정보를 읽어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from djitellopy import Tello\n",
    "import time\n",
    "\n",
    "# Connect to Tello\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "\n",
    "# Start video stream\n",
    "tello.streamon()\n",
    "\n",
    "# Display battery level periodically\n",
    "while True:\n",
    "    # Get battery level\n",
    "    battery_level = tello.get_battery()\n",
    "\n",
    "    # Display battery level\n",
    "    print(f\"Battery Level: {battery_level}%\")\n",
    "\n",
    "    # Wait for 5 seconds\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이제 좀 더 그럴듯하게 해볼까요?\n",
    "### 1) 비행하면서 화면을 보여주면서 배터리 잔량도 동시에 확인합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from djitellopy import Tello\n",
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "\n",
    "def display_video(tello):\n",
    "    while True:\n",
    "        frame = tello.get_frame_read().frame\n",
    "        cv2.imshow(\"Tello Video Feed\", frame)\n",
    "\n",
    "        # Break the loop if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def check_battery(tello):\n",
    "    while True:\n",
    "        battery_level = tello.get_battery()\n",
    "        print(f\"Battery Level: {battery_level}%\")\n",
    "        time.sleep(5)\n",
    "\n",
    "def main():\n",
    "    # Connect to Tello\n",
    "    tello = Tello()\n",
    "    tello.connect()\n",
    "\n",
    "    # Start video stream\n",
    "    tello.streamon()\n",
    "\n",
    "    # Create and start threads for video display and battery check\n",
    "    video_thread = threading.Thread(target=display_video, args=(tello,), daemon=True)\n",
    "    battery_thread = threading.Thread(target=check_battery, args=(tello,), daemon=True)\n",
    "\n",
    "\n",
    "    video_thread.start()\n",
    "    battery_thread.start()\n",
    "\n",
    "    # Takeoff\n",
    "    tello.takeoff()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Rotate clockwise\n",
    "    tello.rotate_clockwise(360)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Land\n",
    "    tello.land()\n",
    "\n",
    "    # Stop video stream\n",
    "    tello.streamoff()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import threading\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 이제는 조종을 해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from djitellopy import Tello\n",
    "import time\n",
    "import threading\n",
    "\n",
    "def check_battery(tello):\n",
    "    while True:\n",
    "        battery_level = tello.get_battery()\n",
    "        print(f\"Battery Level: {battery_level}%\")\n",
    "        time.sleep(5)\n",
    "\n",
    "# Connect to Tello\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "\n",
    "# Create and start threads for video display and battery check\n",
    "battery_thread = threading.Thread(target=check_battery, args=(tello,), daemon=True)\n",
    "battery_thread.start()\n",
    "\n",
    "# Start video stream\n",
    "tello.streamon()\n",
    "\n",
    "# Takeoff\n",
    "tello.takeoff()\n",
    "tello.move_up(50)  # Adjust the height as needed\n",
    "cv2.waitKey(2)  # Give some time for the drone to stabilize\n",
    "\n",
    "# Main loop for face tracking\n",
    "while True:\n",
    "    # Get frame from video stream\n",
    "    frame = tello.get_frame_read().frame\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Tello Video Feed\", frame)\n",
    "\n",
    "    # Capture key presses\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Drone control based on key presses\n",
    "    if key == ord('q'):  # Quit the program\n",
    "        break\n",
    "    elif key == ord('w'):  # Move up\n",
    "        tello.move_up(20)\n",
    "    elif key == ord('s'):  # Move down\n",
    "        tello.move_down(20)\n",
    "    elif key == ord('a'):  # Move left\n",
    "        tello.move_left(20)\n",
    "    elif key == ord('d'):  # Move right\n",
    "        tello.move_right(20)\n",
    "\n",
    "# Land\n",
    "tello.land()\n",
    "\n",
    "# Stop video stream\n",
    "tello.streamoff()\n",
    "\n",
    "# Close OpenCV window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Face detection은 되는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from djitellopy import Tello\n",
    "import time\n",
    "import threading\n",
    "\n",
    "def check_battery(tello):\n",
    "    while True:\n",
    "        battery_level = tello.get_battery()\n",
    "        print(f\"Battery Level: {battery_level}%\")\n",
    "        time.sleep(5)\n",
    "\n",
    "# Connect to Tello\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "\n",
    "# Create and start threads for video display and battery check\n",
    "battery_thread = threading.Thread(target=check_battery, args=(tello,), daemon=True)\n",
    "battery_thread.start()\n",
    "\n",
    "# Start video stream\n",
    "tello.streamon()\n",
    "\n",
    "# Takeoff\n",
    "tello.takeoff()\n",
    "tello.move_up(50)  # Adjust the height as needed\n",
    "cv2.waitKey(2)  # Give some time for the drone to stabilize\n",
    "\n",
    "# Initialize face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# Main loop for face tracking\n",
    "while True:\n",
    "    # Get frame from video stream\n",
    "    frame = tello.get_frame_read().frame\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # If faces are detected, track the first face\n",
    "    if len(faces) > 0:\n",
    "        face = faces[0]\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[0] + face[2], face[1] + face[3]), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Tello Video Feed\", frame)\n",
    "\n",
    "    # Capture key presses\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Drone control based on key presses\n",
    "    if key == ord('q'):  # Quit the program\n",
    "        break\n",
    "    elif key == ord('w'):  # Move up\n",
    "        tello.move_up(20)\n",
    "    elif key == ord('s'):  # Move down\n",
    "        tello.move_down(20)\n",
    "    elif key == ord('a'):  # Move left\n",
    "        tello.move_left(20)\n",
    "    elif key == ord('d'):  # Move right\n",
    "        tello.move_right(20)\n",
    "\n",
    "# Land\n",
    "tello.land()\n",
    "\n",
    "# Stop video stream\n",
    "tello.streamoff()\n",
    "\n",
    "# Close OpenCV window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자, 그럼 이제 object detection을 해볼까요?\n",
    "### 1) 일단 일반적인 object detection\n",
    "#### - 참조할 사이트는 https://github.com/AlexeyAB/darknet\n",
    "#### - coco.names, yolov4-tiny.weights, yolov4-tiny.cfg 파일을 받아 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLOv4 model\n",
    "net = cv2.dnn.readNet(\"yolov4/yolov4-tiny.weights\", \"yolov4/yolov4-tiny.cfg\")\n",
    "classes = []\n",
    "with open(\"yolov4/coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "# Open a video capture\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for webcam, or specify the path to a video file\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Object detection with YOLOv4\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(layer_names)\n",
    "\n",
    "    # Process the results\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                # Object detected, get coordinates\n",
    "                center_x, center_y, w, h = (detection[0:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])).astype('int')\n",
    "                \n",
    "                # Calculate top-left corner\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Draw bounding box and label on the frame\n",
    "                color = (0, 255, 0)  # Green\n",
    "                label = f\"{classes[class_id]}: {confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                cv2.putText(frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"YOLOv4 Object Detection\", frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close OpenCV window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 이제 tello와 결합해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from djitellopy import Tello\n",
    "import time\n",
    "import threading\n",
    "\n",
    "def check_battery(tello):\n",
    "    while True:\n",
    "        battery_level = tello.get_battery()\n",
    "        print(f\"Battery Level: {battery_level}%\")\n",
    "        time.sleep(5)\n",
    "\n",
    "def object_detection(frame, net, classes):\n",
    "    # Object detection with YOLOv4\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(layer_names)\n",
    "\n",
    "    # Process the results\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                # Object detected, get coordinates\n",
    "                center_x, center_y, w, h = (detection[0:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])).astype('int')\n",
    "                \n",
    "                # Calculate top-left corner\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Draw bounding box and label on the frame\n",
    "                color = (0, 255, 0)  # Green\n",
    "                label = f\"{classes[class_id]}: {confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                cv2.putText(frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Connect to Tello\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "\n",
    "# Create and start threads for video display and battery check\n",
    "battery_thread = threading.Thread(target=check_battery, args=(tello,), daemon=True)\n",
    "battery_thread.start()\n",
    "\n",
    "# Start video stream\n",
    "tello.streamon()\n",
    "\n",
    "# Takeoff\n",
    "tello.takeoff()\n",
    "tello.move_up(50)  # Adjust the height as needed\n",
    "cv2.waitKey(2)  # Give some time for the drone to stabilize\n",
    "\n",
    "# Load YOLOv4 model\n",
    "net = cv2.dnn.readNet(\"yolov4/yolov4-tiny.weights\", \"yolov4/yolov4-tiny.cfg\")\n",
    "classes = []\n",
    "with open(\"yolov4/coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "# Main loop for face tracking\n",
    "while True:\n",
    "    # Get frame from video stream\n",
    "    frame = tello.get_frame_read().frame\n",
    "    frame = object_detection(frame, net, classes)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Tello Video Feed\", frame)\n",
    "\n",
    "    # Capture key presses\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Drone control based on key presses\n",
    "    if key == ord('q'):  # Quit the program\n",
    "        break\n",
    "    elif key == ord('w'):  # Move up\n",
    "        tello.move_up(20)\n",
    "    elif key == ord('s'):  # Move down\n",
    "        tello.move_down(20)\n",
    "    elif key == ord('a'):  # Move left\n",
    "        tello.move_left(20)\n",
    "    elif key == ord('d'):  # Move right\n",
    "        tello.move_right(20)\n",
    "\n",
    "# Land\n",
    "tello.land()\n",
    "\n",
    "# Stop video stream\n",
    "tello.streamoff()\n",
    "\n",
    "# Close OpenCV window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 필요한 detection 정보를 빼와 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from djitellopy import Tello\n",
    "import time\n",
    "import threading\n",
    "\n",
    "def check_battery(tello):\n",
    "    while True:\n",
    "        battery_level = tello.get_battery()\n",
    "        print(f\"Battery Level: {battery_level}%\")\n",
    "        time.sleep(5)\n",
    "\n",
    "def object_detection(frame, net, classes):\n",
    "    # Object detection with YOLOv4\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(layer_names)\n",
    "\n",
    "    # Process the results\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                # Object detected, get coordinates\n",
    "                center_x, center_y, w, h = (detection[0:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])).astype('int')\n",
    "                \n",
    "                # Calculate top-left corner\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Draw bounding box and label on the frame\n",
    "                color = (0, 255, 0)  # Green\n",
    "                label = f\"{classes[class_id]}: {confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                cv2.putText(frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Connect to Tello\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "\n",
    "# Create and start threads for video display and battery check\n",
    "battery_thread = threading.Thread(target=check_battery, args=(tello,), daemon=True)\n",
    "battery_thread.start()\n",
    "\n",
    "# Start video stream\n",
    "tello.streamon()\n",
    "\n",
    "# Takeoff\n",
    "tello.takeoff()\n",
    "tello.move_up(50)  # Adjust the height as needed\n",
    "cv2.waitKey(2)  # Give some time for the drone to stabilize\n",
    "\n",
    "# Load YOLOv4 model\n",
    "net = cv2.dnn.readNet(\"yolov4/yolov4-tiny.weights\", \"yolov4/yolov4-tiny.cfg\")\n",
    "classes = []\n",
    "with open(\"yolov4/coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "# Main loop for face tracking\n",
    "while True:\n",
    "    # Get frame from video stream\n",
    "    frame = tello.get_frame_read().frame\n",
    "    frame = object_detection(frame, net, classes)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Tello Video Feed\", frame)\n",
    "\n",
    "    # Capture key presses\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Drone control based on key presses\n",
    "    if key == ord('q'):  # Quit the program\n",
    "        break\n",
    "    elif key == ord('w'):  # Move up\n",
    "        tello.move_up(20)\n",
    "    elif key == ord('s'):  # Move down\n",
    "        tello.move_down(20)\n",
    "    elif key == ord('a'):  # Move left\n",
    "        tello.move_left(20)\n",
    "    elif key == ord('d'):  # Move right\n",
    "        tello.move_right(20)\n",
    "\n",
    "# Land\n",
    "tello.land()\n",
    "\n",
    "# Stop video stream\n",
    "tello.streamoff()\n",
    "\n",
    "# Close OpenCV window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자, 이제는 나만의 모델을 만들어볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 사진을 확보해야 합니다.\n",
    "- 인식하고자 하는 사물의 특성을 잘 파악해야 합니다.\n",
    "- 배경을 다양하게 하는게 중요합니다. (배경이 다양해야 인식하고자 하는 제품만의 특징을 잘 뽑아낼 수 있습니다.)\n",
    "- 충분한 양의 사진을 준비하는 게 중요합니다. (사물당 최소 300장 이상)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 라벨링을 해야합니다.\n",
    "    * Roboflow 서비스를 이용해봅시다. (https://roboflow.com/)\n",
    "    * 안내에 따라 가입하고 Signin 하세요. (Google id로 가입 가능)\n",
    "    \n",
    "    * 프로젝트를 만듭니다.<br>\n",
    "    <img src=\"images/capture14.png\" style=\"width:700px\"><br>\n",
    "    <img src=\"images/capture15.png\" style=\"width:700px\">\n",
    "\n",
    "    * 파일들을 끌어다 놔서 upload 합니다.<br>\n",
    "    <img src=\"images/capture16.png\" style=\"width:700px\">\n",
    "\n",
    "    * 이제 각각의 파일을 열어서 annotation (혹은 라벨링)을 진행합니다. (엄청난 노가다... 그러나... 참을성 있게..)<br>\n",
    "    <img src=\"images/capture17.png\" style=\"width:700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 라벨링이 다 되면 이제 데이터셋을 export 합니다.\n",
    "    * 이렇게 하는 겁니다.<br>\n",
    "    <img src=\"images/capture18.png\" style=\"width:700px\">\n",
    "\n",
    "    * 물론 이때 우리는 yolov8을 선택합니다.<br>\n",
    "    <img src=\"images/capture19.png\" style=\"width:700px\">\n",
    "\n",
    "    * 데이터 셋 파일을 다운로드 받거나, 다운로드 코드를 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 이제 다운 받은 이미지를 한 곳(images)에 모으고 구글 드라이브에 저장합시다.\n",
    "\n",
    "    - 왜냐면 이제는 학습(train)을 위해서 Google colab을 활성화해야 하니까요.\n",
    "    - Train을 위한 프로그램은 이걸 쓸겁니다. (https://colab.research.google.com/drive/1fdAyJwiApi_BT1iiKwqhcfzna2GKpylk)\n",
    "    - 학습이 끝나면 모델은 여러분의 Google Drive에 저장됩니다. (yolov4_backup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yv8env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
