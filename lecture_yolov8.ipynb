{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 언어를 설치합니다.\n",
    "\n",
    "- https://www.python.org/\n",
    "\n",
    "<img src=\"images/img01.png\" style=\"width:700px\"><br>\n",
    "\n",
    "<img src=\"images/image02.png\" style=\"width:700px\"><br>\n",
    "\n",
    "<img src=\"images/image03.png\" style=\"width:700px\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 다운받은 파일을 설치합니다. (주의! 반드시 아래 그림처럼 선택해야 합니다.)\n",
    "\n",
    "<img src=\"images/capture01.PNG\" style=\"width:500px\"><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 python이 잘 작동하는지 확인합시다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/capture02.png\" style=\"width:700px\"><br>\n",
    "\n",
    "<img src=\"images/capture03.png\" style=\"width:700px\"><br>\n",
    "\n",
    "이렇게 나오면 이제 python을 이용할 준비가 끝난 겁니다.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Studio Code를 설치합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://code.visualstudio.com/\n",
    "\n",
    "<img src=\"images/capture04.png\" style=\"width:700px\"><br>\n",
    "\n",
    "- 설치가 끝나면 python 사용이 가능하도록 환경설정을 해줍니다. (그 방법은?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yolov8을 사용할 수 있도록 환경을 구성합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 우선 git 프로그램을 설치합니다.<br>\n",
    "\n",
    "https://git-scm.com/\n",
    "\n",
    "<img src=\"images/capture05.png\" style=\"width:700px\"><br>\n",
    "\n",
    "* 먼저 강의자료 저장소에 접속합니다.<br>\n",
    "\n",
    "https://github.com/greathtj/lectures\n",
    "\n",
    "<img src=\"images/capture06.png\" style=\"width:700px\"><br>\n",
    "\n",
    "* powershell을 이용해서 해당 저장소를 clone 합니다.\n",
    "\n",
    "<img src=\"images/capture07.png\" style=\"width:600px\"><br>\n",
    "\n",
    "\n",
    "* 이제는 YoloV8 공식 사이트에 접속합니다. (https://github.com/ultralytics/ultralytics)\n",
    "\n",
    "<img src=\"images/capture08.png\" style=\"width:700px\"><br>\n",
    "\n",
    "* 강의자료 폴더 안에 clone을 합니다. (\"c:\\lectures\")\n",
    "\n",
    "git clone https://github.com/ultralytics/yolov5.git 실행<br>\n",
    "하지만, 우리의 프로젝트에서는 꼭 clone이 필요한 것은 아닙니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이제 필요한 라이브러리(ultralytics)를 설치합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 먼저 vscode를 이용해서 작업할 수 있도록 준비합니다.\n",
    "\n",
    "<img src=\"images/capture09.png\" style=\"width:700px\"><br>\n",
    "\n",
    "* 새 터미널을 열어서 아래의 명령어를 수행합니다.\n",
    "\n",
    "> python -m venv yv8env<br>\n",
    "> yv8env/Scripts/Activate<br>\n",
    "> pip install ultralytics<br>\n",
    "\n",
    "<img src=\"images/capture10.png\" style=\"width:700px\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이제 OpenCV를 건드려 볼까요?<br>\n",
    "\n",
    "- 그림을 불러서 보여줄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/greathtj/Sync/MyProject/4_kitech/yolov8/yv8env/lib/python3.11/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "frame = cv2.imread(\"2nd_test.jpg\")\n",
    "\n",
    "cv2.imshow(\"image view\", frame)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 웹캠이 있다면 실시간 동영상을 볼 수도 있죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/greathtj/Sync/MyProject/4_kitech/yolov8/yv8env/lib/python3.11/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"webcam test\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key > 0:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그리고 80개의 사물에 대해서 학습한 모델을 실행시켜 봅니다.\n",
    "* coco dataset을 이용해서 미리 학습한 내용입니다.\n",
    "\n",
    "        The COCO (Common Objects in Context) dataset is a widely used benchmark dataset for object detection, instance segmentation, and keypoint detection tasks in computer vision. It provides a large-scale dataset with rich annotations, covering a wide variety of object categories in everyday scenes.\n",
    "\n",
    "        The COCO dataset consists of images from complex everyday scenes, such as street scenes, indoor environments, and natural images. The objects in the images are annotated with bounding boxes, segmentations, and keypoints, providing detailed information about their locations, shapes, and poses. The dataset includes over 200,000 labeled objects across 80 different object categories, making it suitable for training and evaluating object detection and segmentation models.\n",
    "\n",
    "        COCO dataset annotations also include additional information, such as object attributes, relationships between objects, and captions describing the scenes. This makes the dataset valuable not only for object detection tasks but also for tasks related to image understanding and natural language processing.\n",
    "\n",
    "        The COCO dataset is widely used in research and development of computer vision algorithms and serves as a benchmark for evaluating the performance of object detection and segmentation models. It has spurred advancements in various computer vision tasks and has become a standard dataset for evaluating state-of-the-art models in the field.\n",
    "\n",
    "<img src=\"images/capture11.png\" style=\"width:700px\">\n",
    "\n",
    "* coco dataset 모델을 이용한 인식은 yolov8 설치 (pip install ultralytics) 후 만들어진 yolo 라는 프로그램을 이용합니다.\n",
    "        \n",
    "        수행 명령어 입력은 터미널 창에 아래와 같이 입력하세요.\n",
    "\n",
    "        yolo predict model='yolov8n.pt' source='1st_test.jpg'\n",
    "\n",
    "        \n",
    "* 하지만 이 명령을 수행하려면 \"vs_redist.x64.exe\"를 먼저 설치해야 합니다.\n",
    "\n",
    "<img src=\"images/capture12.png\" style=\"width:700px\">\n",
    "\n",
    "* What is Microsoft Visual C++ Redistributable?\n",
    "\n",
    "        Microsoft Visual C++ Redistributable is a collection of runtime components and libraries that are required by certain software applications developed using Microsoft Visual C++. These redistributable packages provide essential runtime support for applications to run properly on Windows operating systems.\n",
    "\n",
    "        When a software program is built using Microsoft Visual C++, it relies on certain dynamic link libraries (DLLs) and runtime components. The Microsoft Visual C++ Redistributable packages include these DLLs and runtime components, ensuring that the necessary dependencies are available on the target system where the application will be installed and run.\n",
    "\n",
    "        The Visual C++ Redistributable packages are installed on the user's system either by the software program itself during installation or by the operating system when required by an application. The packages may include multiple versions of the Visual C++ runtime, as different software applications may depend on different versions.\n",
    "\n",
    "        Having the appropriate version of the Microsoft Visual C++ Redistributable installed on a system ensures that software programs built with Visual C++ can run smoothly, without encountering DLL-related errors or missing runtime dependencies.\n",
    "\n",
    "        It's worth noting that different software programs may require different versions of the Visual C++ Redistributable, so it's common to have multiple versions installed on a system to support various applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/greathtj/Sync/MyProject/4_kitech/yolov8/yv8env/lib/python3.11/site-packages/cv2/qt/plugins\"\n",
      "Ultralytics YOLOv8.0.123 🚀 Python-3.11.2 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Laptop GPU, 7974MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "image 1/1 /home/greathtj/Sync/MyProject/4_kitech/yolov8/1st_test.jpg: 480x640 3 persons, 4 bicycles, 12 cars, 86.4ms\n",
      "Speed: 4.3ms preprocess, 86.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!yolo predict model='yolov8n.pt' source='1st_test.jpg' show=true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* runs/detect/predict# 폴더에 가면 방금 실행한 내용이 결과 사진으로 저장되어 있습니다. (1st_test.jpg)\n",
    "\n",
    "<img src=\"images/capture13.png\" style=\"width:700px\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실시간 카메라 영상을 이용해 봅시다. (우선 yolo 프로그램을 이용해서 해보기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo predict model='yolov8n.pt' source=0 show=true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict한 결과를 이용하기 위해서 필요한 코드 (음... 좀 복잡하긴한데...쩝)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from ultralytics.yolo.utils.plotting import Annotator\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO(\"custom_trained/gates_jobs_musk/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = model.predict(source=img, save=False, show=False, conf=0.3)\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            annotator = Annotator(frame)\n",
    "            for box in boxes:\n",
    "                b = box.xyxy[0]  # get box coordinates in (top, left, bottom, right) format\n",
    "                c = box.cls\n",
    "                cnf = box.conf.item()\n",
    "                b_caption = model.names[int(c)] + f\"_({cnf:.2f})\"\n",
    "                annotator.box_label(b, b_caption)\n",
    "\n",
    "        frame = annotator.result() \n",
    "        cv2.imshow(\"yolov8\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key > 0:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자, 이제는 내 모델을 만들어 볼 차례.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 사진을 확보해야 합니다.\n",
    "- 인식하고자 하는 사물의 특성을 잘 파악해야 합니다.\n",
    "- 배경을 다양하게 하는게 중요합니다. (배경이 다양해야 인식하고자 하는 제품만의 특징을 잘 뽑아낼 수 있습니다.)\n",
    "- 충분한 양의 사진을 준비하는 게 중요합니다. (사물당 최소 300장 이상)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 라벨링을 해야합니다.\n",
    "    * Roboflow 서비스를 이용해봅시다. (https://roboflow.com/)\n",
    "    * 안내에 따라 가입하고 Signin 하세요. (Google id로 가입 가능)\n",
    "    \n",
    "    * 프로젝트를 만듭니다.<br>\n",
    "    <img src=\"images/capture14.png\" style=\"width:700px\"><br>\n",
    "    <img src=\"images/capture15.png\" style=\"width:700px\">\n",
    "\n",
    "    * 파일들을 끌어다 놔서 upload 합니다.<br>\n",
    "    <img src=\"images/capture16.png\" style=\"width:700px\">\n",
    "\n",
    "    * 이제 각각의 파일을 열어서 annotation (혹은 라벨링)을 진행합니다. (엄청난 노가다... 그러나... 참을성 있게..)<br>\n",
    "    <img src=\"images/capture17.png\" style=\"width:700px\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 라벨링이 다 되면 이제 데이터셋을 export 합니다.\n",
    "\n",
    "<img src=\"images/capture18.png\" style=\"width:700px\">\n",
    "\n",
    "* 물론 이때 우리는 yolov8을 선택합니다.<br>\n",
    "<img src=\"images/capture19.png\" style=\"width:700px\">\n",
    "\n",
    "* 데이터 셋 파일을 다운로드 받거나, 다운로드 코드를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"W6heiWaOfMtbe0JEgZzt\")\n",
    "project = rf.workspace(\"korea-institute-of-industrial-technology\").project(\"face-jogph\")\n",
    "dataset = project.version(6).download(\"yolov8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 이제 data.yaml 파일을 수정합니다.\n",
    "\n",
    "<img src=\"images/capture20.png\" style=\"width:700px\"><br>\n",
    "\n",
    "<img src=\"images/capture21.png\" style=\"width:700px\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다운받은 경우는 데이터셋 압축파일을 풀어서 학습 데이터셋을 완성합니다.\n",
    "\n",
    "<img src=\"images/capture22.png\" style=\"width:700px\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 해당 폴더를 반영하여 data.yaml 파일을 편집합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 학습을 진행합니다. (단, GPU가 설치된 컴퓨터가 필요할 겁니다. 그리고 GPU 구동 환경도 만들어줘야겠죠... ㅠㅠ)\n",
    "\n",
    "- 학습 코드<br>\n",
    "\n",
    "* Build a new model from YAML and start training from scratch<br>\n",
    "    >yolo detect train data='face-6/data.yaml' model=yolov8n.yaml epochs=100 imgsz=640\n",
    "\n",
    "* Start training from a pretrained *.pt model<br>\n",
    "    >yolo detect train data='face-6/data.yaml' model=yolov8n.pt epochs=100 imgsz=640\n",
    "\n",
    "* Build a new model from YAML, transfer pretrained weights to it and start training<br>\n",
    "    >yolo detect train data='face-6/data.yaml' model=yolov8n.yaml pretrained=yolov8n.pt epochs=100 imgsz=640\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/capture23.png\" style=\"width:700px\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection을 위한 기본 코드를 만들어봅시다.\n",
    "* 학습이 정상적으로 끝나면 'best.pt'라는 파일이 만들어졌을 겁니다.\n",
    "* 이걸 이용해서 이제 여러분만의 detection (or prediction)을 해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from ultralytics.yolo.utils.plotting import Annotator\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = model.predict(source=img, save=False, show=False, conf=0.3)\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            annotator = Annotator(frame)\n",
    "            for box in boxes:\n",
    "                b = box.xyxy[0]  # get box coordinates in (top, left, bottom, right) format\n",
    "                c = box.cls\n",
    "                cnf = box.conf.item()\n",
    "                b_caption = model.names[int(c)] + f\"_({cnf:.2f})\"\n",
    "                annotator.box_label(b, b_caption)\n",
    "\n",
    "        frame = annotator.result() \n",
    "        cv2.imshow(\"yolov8\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key > 0:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
